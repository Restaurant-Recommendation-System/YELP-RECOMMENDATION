{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = open('user_5k_avg', 'r').read()\n",
    "user_avg = eval(f1)\n",
    "\n",
    "f2 = open('business_5k_avg', 'r').read()\n",
    "business_avg = eval(f2)\n",
    "\n",
    "f3 = open('review_5k_user', 'r').read()\n",
    "review5k_user = eval(f3)\n",
    "\n",
    "f4 = open('review_5k_business', 'r').read()\n",
    "review5k_business = eval(f4)\n",
    "\n",
    "f5 = open('review_5k_rating', 'r').read()\n",
    "review5k_rating = eval(f5)\n",
    "\n",
    "f6 = open('review_5k_text', 'r').read()\n",
    "review5k_text = eval(f6)\n",
    "\n",
    "f7 = open('relation_5k', 'r').read()\n",
    "relation = eval(f7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Parameters</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_user = review5k_user[0:45000]\n",
    "train_business = review5k_business[0:45000]\n",
    "train_rating = review5k_rating[0:45000]\n",
    "train_text = review5k_text[0:45000]\n",
    "\n",
    "test_user = review5k_user[45000:]\n",
    "test_business = review5k_business[45000:]\n",
    "test_rating = review5k_rating[45000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K_topic = 10 \n",
    "Times = 5000\n",
    "DocWord = 300\n",
    "DocTopic = 30\n",
    "SVD_model = 0 # [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# U, S, VT = randomized_svd(BasicIn, n_components=K_topic, n_iter=Times, random_state=None)\n",
    "# U, S, VT = svds(BasicIn, k=K_topic, which='LM', maxiter = Times, return_singular_vectors=True)\n",
    "'''rc4s = []\n",
    "for n in xrange(K_topic):\n",
    "    rc4s.append(n)\n",
    "rc4s = np.array(rc4s)\n",
    "S = csr_matrix((S,(rc4s,rc4s)), shape=(K_topic, K_topic)).toarray()\n",
    "BasicOut = np.dot(np.dot(U,S),VT)'''\n",
    "\n",
    "\n",
    "def SVD(In):\n",
    "    svd = TruncatedSVD(n_components=K_topic, n_iter=Times, random_state=None)\n",
    "    U = svd.fit_transform(In)\n",
    "    VT = svd.components_\n",
    "    BasicOut = np.dot(U,VT)\n",
    "    return Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>No Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_user = len(user_avg)\n",
    "num_business = len(business_avg)\n",
    "num_train = len(train_rating)\n",
    "num_test = len(test_rating)\n",
    "\n",
    "mu = np.mean(train_rating)\n",
    "\n",
    "ubb = []\n",
    "for i in xrange(len(user_avg)):\n",
    "    ubb.append([])\n",
    "    for j in xrange(len(business_avg)):\n",
    "        ubb[i].append(user_avg[i] + business_avg[j] - mu) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854368016052\n"
     ]
    }
   ],
   "source": [
    "UbbPd = []\n",
    "for r in xrange(num_test):\n",
    "    UbbPd.append(ubb[test_user[r]][test_business[r]]) \n",
    "\n",
    "Ubb_rmse = mean_squared_error(test_rating, UbbPd)  \n",
    "\n",
    "print Ubb_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Basic Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delta_basic = []\n",
    "for r in xrange(len(train_rating)):\n",
    "    delta_basic.append(train_rating[r] - ubb[train_user[r]][train_business[r]]) \n",
    "\n",
    "row = np.array(train_user)\n",
    "col = np.array(train_business)\n",
    "val = np.array(delta_basic)\n",
    "\n",
    "BasicIn = csr_matrix((val,(row,col)), shape=(num_user, num_business)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "U = svd.fit_transform(BasicIn)\n",
    "VT = svd.components_\n",
    "BasicOut = np.dot(U,VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.90997788e-04,  -1.86532125e-18,  -9.71325391e-04, ...,\n",
       "         -1.23634225e-02,  -1.08976530e-02,  -2.09044077e-02],\n",
       "       [ -2.84528887e-03,   7.50965024e-17,   6.14505204e-03, ...,\n",
       "         -8.84735035e-02,  -1.06266987e-01,  -7.64334881e-03],\n",
       "       [ -2.68832488e-03,   1.99525243e-17,   2.27058253e-03, ...,\n",
       "         -1.13645805e-02,  -3.63315975e-02,  -1.73916929e-02],\n",
       "       ..., \n",
       "       [  4.04948153e-04,   2.75654208e-20,   2.90080501e-04, ...,\n",
       "         -6.05942588e-03,  -3.73982935e-04,  -5.13101855e-03],\n",
       "       [ -3.49385933e-02,   4.81971278e-16,   2.99101389e-02, ...,\n",
       "         -3.72007405e-01,  -6.18409051e-01,   1.99592743e-02],\n",
       "       [  1.65008363e-03,   1.12323637e-19,   1.18202067e-03, ...,\n",
       "         -2.46909619e-02,  -1.52390649e-03,  -2.09078857e-02]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BasicOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BasicOut = SVD(BasicIn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(BasicOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854402441609\n"
     ]
    }
   ],
   "source": [
    "BasicPd = []\n",
    "for r in xrange(num_test):\n",
    "    BasicPd.append(ubb[test_user[r]][test_business[r]] + BasicOut[test_user[r]][test_business[r]]) \n",
    "\n",
    "Basic_rmse = mean_squared_error(test_rating, BasicPd)  \n",
    "\n",
    "print Basic_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print mean_squared_error(BasicIn, BasicOut) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Topic Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "en_stop = get_stop_words('en')\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "def prep(doc):\n",
    "    raw = doc.lower().replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    texts = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    return (\" \").join(texts)\n",
    "\n",
    "Breview = [\"\"]*num_business\n",
    "for r in xrange(num_train):\n",
    "    Breview[train_business[r]] += prep(train_text[r])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=DocWord, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(Breview)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=DocTopic, max_iter=5, learning_method='online',learning_offset=50.,random_state=0)\n",
    "DocTopicDist = lda.fit_transform(tf)\n",
    "\n",
    "DocCosine_norm = []\n",
    "for n in xrange(num_business):\n",
    "    DocCosine_norm.append(math.sqrt(np.dot(DocTopicDist[n], DocTopicDist[n])))\n",
    "\n",
    "for n in xrange(num_business):\n",
    "    DocTopicDist[n] = 1.0*DocTopicDist[n]/DocCosine_norm[n]\n",
    "    \n",
    "DocSim = np.dot(DocTopicDist, DocTopicDist.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delta_temp1 = {}\n",
    "for n in xrange(num_business):\n",
    "    delta_temp1[n] = []\n",
    "for n in xrange(num_train):\n",
    "    delta_temp1[train_business[n]].append(delta_basic[n])\n",
    "\n",
    "delta_temp2 = []\n",
    "for n in xrange(num_business):\n",
    "    if n in train_business:\n",
    "        delta_temp2.append(np.mean(delta_temp1[n]))\n",
    "    else:\n",
    "        delta_temp2.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TopicModify = []\n",
    "for n in xrange(num_business):\n",
    "    TopicModify.append(np.dot(DocSim[n],delta_temp2)/sum(DocSim[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delta_topic = []\n",
    "for r in xrange(len(train_rating)):\n",
    "    delta_topic.append(train_rating[r] - ubb[train_user[r]][train_business[r]] - TopicModify[train_business[r]]) \n",
    "\n",
    "row = np.array(train_user)\n",
    "col = np.array(train_business)\n",
    "val = np.array(delta_topic)\n",
    "TopicIn = csr_matrix((val,(row,col)), shape=(num_user, num_business)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U, S, VT = randomized_svd(TopicIn, n_components=K_topic, n_iter=Times, random_state=None)\n",
    "rc4s = []\n",
    "for n in xrange(K_topic):\n",
    "    rc4s.append(n)\n",
    "rc4s = np.array(rc4s)\n",
    "S = csr_matrix((S,(rc4s,rc4s)), shape=(K_topic, K_topic)).toarray()\n",
    "\n",
    "TopicOut = np.dot(np.dot(U,S),VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BasicPd = []\n",
    "for r in xrange(num_test):\n",
    "    BasicPd.append(ubb[test_user[r]][test_business[r]] + TopicModify[test_business[r]] + BasicOut[test_user[r]][test_business[r]]) \n",
    "\n",
    "Basic_rmse = mean_squared_error(test_rating, BasicPd)  \n",
    "\n",
    "print Basic_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Topic Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "node_list = []\n",
    "for u in xrange(num_user):\n",
    "    node_list.append(u)\n",
    "\n",
    "G=nx.Graph()\n",
    "G.add_nodes_from(node_list)\n",
    "for u in relation:\n",
    "    for f in u[1]:\n",
    "        G.add_edge(u[0], f)\n",
    "\n",
    "PR = nx.pagerank(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "sorted_PR = sorted(PR.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "rank_dict = {}\n",
    "for u in xrange(num_user):\n",
    "    rank_dict[sorted_PR[u][0]] = u\n",
    "    \n",
    "rank_list = []\n",
    "for u in xrange(num_user):\n",
    "    rank_list.append(rank_dict[u]+1)\n",
    "\n",
    "rank_weight = []\n",
    "for ri in rank_list:\n",
    "    rank_weight.append(1.0/(1.0+ math.log(ri)))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delta_temp3 = {}\n",
    "for n in xrange(num_user):\n",
    "    delta_temp3[n] = []\n",
    "for n in xrange(num_train):\n",
    "    delta_temp3[train_user[n]].append(delta_basic[n])\n",
    "\n",
    "delta_temp4 = []\n",
    "for n in xrange(num_user):\n",
    "    if n in train_user:\n",
    "        delta_temp4.append(np.mean(delta_temp3[n]))\n",
    "    else:\n",
    "        delta_temp4.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SocialModify = []\n",
    "for n in xrange(num_user):\n",
    "    SocialModify.append(np.dot(DocSim[n],delta_temp4)/sum(DocSim[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
