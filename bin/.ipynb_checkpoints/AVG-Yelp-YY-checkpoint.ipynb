{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Initialization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1 = open('../5k-data/user_5k_avg', 'r').read()\n",
    "user_avg = eval(f1)\n",
    "\n",
    "f2 = open('../5k-data/business_5k_avg', 'r').read()\n",
    "business_avg = eval(f2)\n",
    "\n",
    "f3 = open('../5k-data/review_5k_user', 'r').read()\n",
    "review5k_user = eval(f3)\n",
    "\n",
    "f4 = open('../5k-data/review_5k_business', 'r').read()\n",
    "review5k_business = eval(f4)\n",
    "\n",
    "f5 = open('../5k-data/review_5k_rating', 'r').read()\n",
    "review5k_rating = eval(f5)\n",
    "\n",
    "f6 = open('../5k-data/review_5k_text', 'r').read()\n",
    "review5k_text = eval(f6)\n",
    "\n",
    "f7 = open('../5k-data/relation_5k', 'r').read()\n",
    "relation = eval(f7)\n",
    "\n",
    "import random \n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "en_stop = get_stop_words('en')\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "def prep(doc):\n",
    "    raw = doc.lower().replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    texts = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    return (\" \").join(texts)\n",
    "\n",
    "from sklearn import linear_model\n",
    "def MLR(X, Y):\n",
    "    reg = linear_model.LinearRegression()\n",
    "    reg.fit(X, Y)\n",
    "    return reg.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Parameter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K_topic = 10\n",
    "Times = 50\n",
    "DocWord = 300\n",
    "DocTopic = 5\n",
    "\n",
    "sim_val = 0.85\n",
    "vip_val = 0.2\n",
    "lbd0 = 0.5 # Topic effect\n",
    "lbd2 = 0.4 # relation afftect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Process</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def Process():\n",
    "    train_user = []\n",
    "    train_business = []\n",
    "    train_rating = []\n",
    "    train_text = []\n",
    "\n",
    "    test_user = []\n",
    "    test_business = []\n",
    "    test_rating = []\n",
    "    \n",
    "    random_test = random.sample(xrange(len(review5k_rating)), 1000)\n",
    "\n",
    "    for r in xrange(len(review5k_rating)):\n",
    "        if r in random_test:\n",
    "            test_user.append(review5k_user[r])\n",
    "            test_business.append(review5k_business[r])\n",
    "            test_rating.append(review5k_rating[r])\n",
    "        else:\n",
    "            train_user.append(review5k_user[r])\n",
    "            train_business.append(review5k_business[r])\n",
    "            train_rating.append(review5k_rating[r])\n",
    "            train_text.append(review5k_text[r])\n",
    "   \n",
    "    num_user = len(user_avg)\n",
    "    num_business = len(business_avg)\n",
    "    num_train = len(train_rating)\n",
    "    num_test = len(test_rating)\n",
    "    mu = np.mean(train_rating)\n",
    "\n",
    "    ##### Ubb Model #####\n",
    "    Ubb = []\n",
    "    for i in xrange(num_user):\n",
    "        Ubb.append([])\n",
    "        for j in xrange(num_business):\n",
    "            val = user_avg[i] + business_avg[j] - mu\n",
    "            if val < 1: val = 1\n",
    "            if val > 5: val = 5\n",
    "            Ubb[i].append(val) \n",
    "        \n",
    "    UbbPd = []\n",
    "    for r in xrange(num_test):\n",
    "        UbbPd.append(Ubb[test_user[r]][test_business[r]]) \n",
    "\n",
    "    Ubb_rmse = mean_squared_error(test_rating, UbbPd)  \n",
    "\n",
    "    ##### Basic Model #####\n",
    "    BasicIn = []\n",
    "    for i in xrange(num_user):\n",
    "        BasicIn.append([])\n",
    "        for j in xrange(num_business):\n",
    "            val = user_avg[i] + business_avg[j] - mu\n",
    "            if val < 1: val = 1\n",
    "            if val > 5: val = 5\n",
    "            BasicIn[i].append(val) \n",
    "\n",
    "    for r in xrange(num_train):\n",
    "        BasicIn[train_user[r]][train_business[r]] = train_rating[r]\n",
    "\n",
    "    model = NMF(n_components=K_topic, init='random', random_state=0)\n",
    "    U = model.fit_transform(BasicIn);\n",
    "    V = model.components_;\n",
    "    BasicOut = np.dot(U,V)        \n",
    "        \n",
    "    BasicPd = []\n",
    "    for r in xrange(num_test):\n",
    "        BasicPd.append(BasicOut[test_user[r]][test_business[r]]) \n",
    "\n",
    "    BasicPd_rmse = mean_squared_error(test_rating, BasicPd)  \n",
    "    \n",
    "    ##### Topic Model #####\n",
    "    Breview = [\"\"]*num_business\n",
    "    for r in xrange(num_train):\n",
    "        Breview[train_business[r]] += prep(train_text[r])\n",
    "\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=DocWord, stop_words='english')\n",
    "    tf = tf_vectorizer.fit_transform(Breview)\n",
    "\n",
    "    lda = LatentDirichletAllocation(n_topics=DocTopic, max_iter=5, learning_method='online',learning_offset=50.,random_state=0)\n",
    "    DocTopDist = lda.fit_transform(tf)\n",
    "\n",
    "    row = np.array([])\n",
    "    col = np.array([])\n",
    "    val = np.array([])\n",
    "\n",
    "    # delta -> difference between rating and ubb [u*b], delta2 -> rating boolean\n",
    "    delta = csr_matrix((val,(row,col)), shape=(num_user,num_business)).toarray()\n",
    "    delta2 = csr_matrix((val,(row,col)), shape=(num_user,num_business)).toarray()\n",
    "    for r in xrange(num_train):\n",
    "        delta[train_user[r]][train_business[r]] = train_rating[r] - Ubb[train_user[r]][train_business[r]]\n",
    "        delta2[train_user[r]][train_business[r]] = 1\n",
    "        \n",
    "    deltaReg = []\n",
    "    for i in xrange(num_user):\n",
    "        X = [[0,0,0,0,0], [1,0,0,0,0], [0,1,0,0,0], [0,0,1,0,0], [0,0,0,1,0], [0,0,0,0,1]]; Y = [0,0,0,0,0,0]\n",
    "        for j in xrange(num_business):\n",
    "            if delta2[i][j]:\n",
    "                X.append(list(DocTopDist[j]))\n",
    "                Y.append(delta[i][j])\n",
    "        coef = MLR(X, Y)\n",
    "        deltaReg.append(np.dot(DocTopDist, coef))\n",
    "            \n",
    "    row = np.array([])\n",
    "    col = np.array([])\n",
    "    val = np.array([])\n",
    "    TopicIn = csr_matrix((val,(row,col)), shape=(num_user,num_business)).toarray()\n",
    "    for i in xrange(num_user):\n",
    "        for j in xrange(num_business):\n",
    "            val = Ubb[i][j] + lbd0*deltaReg[i][j]\n",
    "            if val < 1: val = 1\n",
    "            if val > 5: val = 5\n",
    "            TopicIn[i][j] = val\n",
    "\n",
    "    TopicInPd = []\n",
    "    for r in xrange(num_test):\n",
    "        TopicInPd.append(TopicIn[test_user[r]][test_business[r]]) \n",
    "\n",
    "    TopicInPd_rmse = mean_squared_error(test_rating, TopicInPd)  \n",
    "\n",
    "    ##### Social Model #####\n",
    "    PR = {}\n",
    "    for u in relation:\n",
    "        PR[u[0]] = len(u[1])\n",
    "\n",
    "    from operator import itemgetter\n",
    "    sorted_PR = sorted(PR.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "    rank = {}\n",
    "    for u in xrange(num_user):\n",
    "        rank[sorted_PR[u][0]] = u+1\n",
    "\n",
    "    Ri = []\n",
    "    for u in xrange(num_user):\n",
    "        Ri.append(rank[u])\n",
    "\n",
    "    Wi = []\n",
    "    for ri in Ri:\n",
    "        Wi.append(1.0/(1.0+ math.log(ri)))    \n",
    "    \n",
    "    row = np.array([])\n",
    "    col = np.array([])\n",
    "    val = np.array([])\n",
    "\n",
    "    Rij = csr_matrix((val,(row,col)), shape=(num_user,num_business)).toarray()\n",
    "    Sij = csr_matrix((val,(row,col)), shape=(num_user,num_business)).toarray()\n",
    "    Tij = csr_matrix((val,(row,col)), shape=(num_user,num_user)).toarray()\n",
    "    Uij = csr_matrix((val,(row,col)), shape=(num_user,num_user)).toarray()\n",
    "\n",
    "    # user-item rating matrix. If ui gives a rating to vj, Rij is the rating score, otherwise 0\n",
    "    for r in xrange(num_train):\n",
    "        Rij[train_user[r]][train_business[r]] = train_rating[r] - Ubb[train_user[r]][train_business[r]]\n",
    "        Sij[train_user[r]][train_business[r]] = 1\n",
    "\n",
    "    # user-user social relations where Tij = 1 if ui,uj has a relation and zero otherwise\n",
    "    for u in relation:\n",
    "        for f in u[1]:\n",
    "            Tij[u[0]][f] = 1\n",
    "\n",
    "    TR = np.dot(Tij, Rij)\n",
    "    TS = np.dot(Tij, Sij)\n",
    "\n",
    "    row = np.array([])\n",
    "    col = np.array([])\n",
    "    val = np.array([])\n",
    "    Vij2 = csr_matrix((val,(row,col)), shape=(num_user,num_business)).toarray()\n",
    "\n",
    "    for i in xrange(num_user):\n",
    "        for j in xrange(num_business):\n",
    "            if TS[i][j]: Vij2[i][j] = lbd2*TR[i][j]/TS[i][j]\n",
    "\n",
    "    row = np.array([])\n",
    "    col = np.array([])\n",
    "    val = np.array([])\n",
    "    SocialIn2 = csr_matrix((val,(row,col)), shape=(num_user,num_business)).toarray()\n",
    "\n",
    "    for i in xrange(num_user):\n",
    "        for j in xrange(num_business):\n",
    "            val2 = Ubb[i][j] + Vij2[i][j]\n",
    "\n",
    "            if val2 < 1: val2 = 1\n",
    "            if val2 > 5: val2 = 5\n",
    "\n",
    "            SocialIn2[i][j] = val2\n",
    "\n",
    "    SocialInPd2 = []\n",
    "\n",
    "    for r in xrange(num_test):\n",
    "        SocialInPd2.append(SocialIn2[test_user[r]][test_business[r]]) \n",
    "\n",
    "    SocialInPd_rmse = mean_squared_error(test_rating, SocialInPd2) \n",
    "    \n",
    "    print \"---------------------\"\n",
    "    print \"Ubb_rmse =\", Ubb_rmse\n",
    "    print \"BasicPd_rmse =\", BasicPd_rmse\n",
    "    print \"TopicInPd_rmse =\", TopicInPd_rmse\n",
    "    print \"SocialInPd_rmse =\", SocialInPd_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in xrange(10):\n",
    "    Process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
